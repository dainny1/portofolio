{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import nltk\n",
    "import openpyxl\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.formats.excel\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_excel(path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_name(data):\n",
    "    service_name = pd.DataFrame(data['SERVICE_NAME'])\n",
    "    return service_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_service_type(data, types):\n",
    "    data = data[data['SERVICE_TYPE'].isin(types)]\n",
    "    data.reset_index(inplace=True,drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standards_path():\n",
    "    paths = []\n",
    "    for file in os.listdir(\"Standards\"):\n",
    "        paths.append(os.path.join(\"Standards\", file))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_standards(paths):\n",
    "    stds = []\n",
    "    for path in paths:\n",
    "        stds.append(pd.read_excel(path))\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_providers_path():\n",
    "    paths = []\n",
    "    for file in os.listdir(\"Providers\"):\n",
    "        paths.append(os.path.join(\"Providers\", file))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document(DF1,col_index): #DF1 is the DF to be preprocessed #col_index is the number of the describtion column (int)\n",
    "    # Making A copy to prevent change to the original DF as it is needd subsequently\n",
    "    DF = DF1.copy()\n",
    "    # Insuring string type for the wanted col\n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].astype(str)\n",
    "    # Removing all newline and replacing it with space\n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].str.replace('\\n',' ')\n",
    "    #Replacing all non alphanumeric in both english and arabic by space\n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: re.sub('[^0-9a-zA-Z\\u0627-\\u064a]+', ' ', x))\n",
    "    #Separating camel case with space \n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", x))\n",
    "    #lowercasing all describtions\n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x:''.join(i for i in x if not i.isdigit()))\n",
    "    #In case a med dict present (referring the medical abbreviation to its origin) this line return the abbreviation to origin\n",
    "    ## DF_document.document = DF_document.document.apply(lambda x: \" \".join(med_dict(word) for word in x.split()) )\n",
    "    #Counting all Words that occur either in very low freq or very high and removing them (Threshhold must be configured)\n",
    "    ## freq = pd.Series(' '.join(DF[DF.columns[col_index]]).split()).value_counts()[:50]\n",
    "    ## DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: \" \".join(x for x in x.split() if  x not in freq.index))\n",
    "    ## freq = pd.Series(' '.join(DF[DF.columns[col_index]]).split()).value_counts()[-1034:]\n",
    "    ## DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: \" \".join(x for x in x.split() if x not in freq.index))\n",
    "    #Defining a stemmer and stemming all words in the description\n",
    "    st = PorterStemmer()\n",
    "    #DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "    DF[DF.columns[col_index]] = DF[DF.columns[col_index]].apply(lambda x: \"\" if x.isdigit() == True else x)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(service_name,standards):\n",
    "    DF = pd.concat(objs = [service_name,standards])\n",
    "    DF = DF.apply(lambda x: ''.join(i for i in x if not i.isdigit()))\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer(df,service_name,standard):\n",
    "    stopWords = stopwords.words('english')\n",
    "    tfidf = TfidfVectorizer(stop_words=stopWords)\n",
    "    tfidf.fit(df)\n",
    "    tfref = tfidf.transform(standard)\n",
    "    tfdata = tfidf.transform(service_name)\n",
    "    return tfref,tfdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(tfidf_data,tfidf_ref, index, rank = 0):\n",
    "    #multiplying the 2 matrix to find the cosine similarity\n",
    "    cosine_similarities = linear_kernel(tfidf_data[index:index+1], tfidf_ref[:]).flatten()\n",
    "    #getting the most similar index\n",
    "    highest_ind = cosine_similarities.argsort()[::-1][rank]\n",
    "    #return the index along with its similarity\n",
    "    return highest_ind, cosine_similarities[highest_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(data,tfdata,tfref):\n",
    "    result = pd.DataFrame(columns = ['Serv','cpt','Sim','Num'])\n",
    "    resultAll = pd.DataFrame(columns = ['Serv','cpt','Sim','Num'])\n",
    "    for i in range(len(data)):\n",
    "        for j in range(0,1):\n",
    "            index, simlarity = find_similar(tfdata, tfref, i, j)\n",
    "            result.loc[i] = [i, index, simlarity, j]\n",
    "            resultAll = resultAll.append(result)\n",
    "            result.drop(result.index, inplace = True)\n",
    "    return resultAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_results(result_ACHI, result_SFDA, result_CPT):\n",
    "    df = pd.DataFrame(columns=['Serv','cpt','Sim','Num','Mapped_Code'])\n",
    "    for i in range(len(result_ACHI)):\n",
    "        sims=[result_ACHI.iloc[i,2], result_SFDA.iloc[i,2], result_CPT.iloc[i,2]]\n",
    "        if np.argmax(np.array(sims)) == 0:\n",
    "            df.loc[i] = result_ACHI.iloc[i].to_list() + ['ACHI']\n",
    "        elif np.argmax(np.array(sims)) == 1:\n",
    "            df.loc[i] = result_SFDA.iloc[i].to_list() + ['SFDA']\n",
    "        elif np.argmax(np.array(sims)) == 2:\n",
    "            df.loc[i] = result_CPT.iloc[i].to_list() + ['CPT']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_map(data,result,ACHI,SFDA,CPT):\n",
    "    data['Mapped_Code'] = result['Mapped_Code']\n",
    "    for i in range(len(data)):\n",
    "        if result.iloc[i,4] == 'ACHI':\n",
    "            data.loc[i, 'Unified_Code'] = ACHI.iloc[int(result.iloc[i,1]),0]\n",
    "            data.loc[i, 'Unified_Code_Description'] = ACHI.iloc[int(result.iloc[i,1]),3]\n",
    "        elif result.iloc[i,4] == 'SFDA':\n",
    "            data.loc[i, 'Unified_Code'] = SFDA.iloc[int(result.iloc[i,1]),0]\n",
    "            data.loc[i, 'Unified_Code_Description'] = SFDA.iloc[int(result.iloc[i,1]),3]\n",
    "        elif result.iloc[i,4] == 'CPT':\n",
    "            data.loc[i, 'Unified_Code'] = CPT.iloc[int(result.iloc[i,1]),0]\n",
    "            data.loc[i, 'Unified_Code_Description'] = CPT.iloc[int(result.iloc[i,1]),1]\n",
    "            \n",
    "    data['Similarity'] = result['Sim']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_similarity(data, thresh):\n",
    "    data.loc[data['Similarity'] < thresh, ['Unified_Code','Unified_Code_Description','Mapped_Code']] = 'Not Found!'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_mapping(data_path):\n",
    "    data = read_data(data_path)\n",
    "    data = get_data_by_service_type(data, ['Lab','Diagnosis Procedure','Dental','Diagnostic Procedures','Other Medical Services','Package Deal','Physiotherapy','Radiology'])\n",
    "    ACHI, ACHI_3ADDA, CPT, SFDA = read_standards(get_standards_path())\n",
    "    service_name = get_service_name(data)\n",
    "    \n",
    "    ACHI_processed = create_document(ACHI,3)\n",
    "    SFDA_processed = create_document(SFDA,3)\n",
    "    CPT_processed = create_document(CPT,1)\n",
    "    data_processed = create_document(service_name,0)\n",
    "    \n",
    "    if len(data_processed) > 0:\n",
    "        tfref_ACHI,tfdata_ACHI = create_vectorizer(concat(data_processed['SERVICE_NAME'],ACHI_processed['ascii_desc']),data_processed['SERVICE_NAME'],ACHI_processed['ascii_desc'])\n",
    "        tfref_SFDA,tfdata_SFDA = create_vectorizer(concat(data_processed['SERVICE_NAME'],SFDA_processed['intended_purpose']),data_processed['SERVICE_NAME'],SFDA_processed['intended_purpose'])\n",
    "        tfref_CPT,tfdata_CPT = create_vectorizer(concat(data_processed['SERVICE_NAME'],CPT_processed['LongDescription']),data_processed['SERVICE_NAME'],CPT_processed['LongDescription'])\n",
    "\n",
    "        resultAll_ACHI = get_similarity(data,tfdata_ACHI,tfref_ACHI)\n",
    "        resultAll_SFDA = get_similarity(data,tfdata_SFDA,tfref_SFDA)\n",
    "        resultAll_CPT = get_similarity(data,tfdata_CPT,tfref_CPT)\n",
    "\n",
    "        AllResult = get_max_results(resultAll_ACHI,resultAll_SFDA,resultAll_CPT)\n",
    "        AllResult = do_map(data,AllResult,ACHI,SFDA,CPT)\n",
    "        #AllResult = filter_by_similarity(AllResult, 0.6)\n",
    "    else:\n",
    "        AllResult = []\n",
    "\n",
    "    return AllResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_excel(path):\n",
    "    writer = pd.ExcelWriter(path,engine='openpyxl')\n",
    "    #writer.book = openpyxl.load_workbook(path).sheetnames\n",
    "    \n",
    "    pandas.io.formats.excel.ExcelFormatter.header_style = None\n",
    "    \n",
    "    result.to_excel(writer,sheet_name=openpyxl.load_workbook(path).sheetnames[0],index=False)\n",
    "    \n",
    "    for i, sheetname in enumerate(writer.book.sheetnames):\n",
    "        worksheet = writer.book[sheetname]\n",
    "        mediumStyle = openpyxl.worksheet.table.TableStyleInfo(name='TableStyleMedium2',showRowStripes=True)\n",
    "        table = openpyxl.worksheet.table.Table(ref=worksheet.dimensions,displayName=\"Table\" + str(i),tableStyleInfo=mediumStyle)\n",
    "        worksheet.add_table(table)\n",
    "        \n",
    "        for col in worksheet.columns:\n",
    "            worksheet.column_dimensions[col[0].column_letter].width = (len(str(col[0].value)) + 2) * 1.2\n",
    "    \n",
    "    writer.book.save(path)\n",
    "    writer.book.close()\n",
    "    writer.close()\n",
    "    os.rename(path,os.path.join(\"Mapped Providers 2\",os.path.splitext(os.path.basename(path))[0]+\" Mapped\"+os.path.splitext(path)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started mapping Hayat National Hospital - Qassim ## 6212000853 @ 3603.xlsx\n",
      "Finished mapping Hayat National Hospital - Qassim ## 6212000853 @ 3603.xlsx\n",
      "Exported Hayat National Hospital - Qassim ## 6212000853 @ 3603.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:03:42\n",
      "\n",
      "Started mapping Hiba Asia Polyclinic ## 6212000646 @ 6949.xlsx\n",
      "Finished mapping Hiba Asia Polyclinic ## 6212000646 @ 6949.xlsx\n",
      "Exported Hiba Asia Polyclinic ## 6212000646 @ 6949.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:21\n",
      "\n",
      "Started mapping Hiba Asia Polyclinic 2 Jeddah ## 6212000690 @ 6949.xlsx\n",
      "Finished mapping Hiba Asia Polyclinic 2 Jeddah ## 6212000690 @ 6949.xlsx\n",
      "Exported Hiba Asia Polyclinic 2 Jeddah ## 6212000690 @ 6949.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:00:59\n",
      "\n",
      "Started mapping Jeddah National Hospital ## 6212000297 @ 1652.xlsx\n",
      "Finished mapping Jeddah National Hospital ## 6212000297 @ 1652.xlsx\n",
      "Exported Jeddah National Hospital ## 6212000297 @ 1652.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:50\n",
      "\n",
      "Started mapping Maha Al Khamis-1 Al Nassem ## 6212000558 @ 365.xlsx\n",
      "There is no mappings for this provider\n",
      "Started mapping Mohammed Al Dossary Hospital ## 6212000782 @ 9677.xlsx\n",
      "Finished mapping Mohammed Al Dossary Hospital ## 6212000782 @ 9677.xlsx\n",
      "Exported Mohammed Al Dossary Hospital ## 6212000782 @ 9677.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:03:17\n",
      "\n",
      "Started mapping Obeid Specialized Hospital - Riyadh ## 6212000073 @ 4726.xlsx\n",
      "Finished mapping Obeid Specialized Hospital - Riyadh ## 6212000073 @ 4726.xlsx\n",
      "Exported Obeid Specialized Hospital - Riyadh ## 6212000073 @ 4726.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:04:17\n",
      "\n",
      "Started mapping Rabiah Hospital ## 6212000557 @ 2703.xlsx\n",
      "Finished mapping Rabiah Hospital ## 6212000557 @ 2703.xlsx\n",
      "Exported Rabiah Hospital ## 6212000557 @ 2703.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:03:02\n",
      "\n",
      "Started mapping Safa Makkah Polyclinic 1 ## 6212000106 @ 255.xlsx\n",
      "Finished mapping Safa Makkah Polyclinic 1 ## 6212000106 @ 255.xlsx\n",
      "Exported Safa Makkah Polyclinic 1 ## 6212000106 @ 255.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:00:54\n",
      "\n",
      "Started mapping Safa Makkah Polyclinic 2 ## 6212000086 @ 505.xlsx\n",
      "Finished mapping Safa Makkah Polyclinic 2 ## 6212000086 @ 505.xlsx\n",
      "Exported Safa Makkah Polyclinic 2 ## 6212000086 @ 505.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:03\n",
      "\n",
      "Started mapping Safa Medical Center - Dammam ## 6212000673 @ 543.xlsx\n",
      "Finished mapping Safa Medical Center - Dammam ## 6212000673 @ 543.xlsx\n",
      "Exported Safa Medical Center - Dammam ## 6212000673 @ 543.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:00\n",
      "\n",
      "Started mapping Saudi National Hospital ## 6212000338 @ 970.xlsx\n",
      "Finished mapping Saudi National Hospital ## 6212000338 @ 970.xlsx\n",
      "Exported Saudi National Hospital ## 6212000338 @ 970.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:20\n",
      "\n",
      "Started mapping Shifa Al Khobar Polyclinic ## 6212000600 @ 598.xlsx\n",
      "Finished mapping Shifa Al Khobar Polyclinic ## 6212000600 @ 598.xlsx\n",
      "Exported Shifa Al Khobar Polyclinic ## 6212000600 @ 598.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:01\n",
      "\n",
      "Started mapping Shifa Al-jazeera Polyclinic ## 6212000102 @ 613.xlsx\n",
      "Finished mapping Shifa Al-jazeera Polyclinic ## 6212000102 @ 613.xlsx\n",
      "Exported Shifa Al-jazeera Polyclinic ## 6212000102 @ 613.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:04\n",
      "\n",
      "Started mapping Shifa Buraydah Polyclinic ## 6212000141 @ 473.xlsx\n",
      "Finished mapping Shifa Buraydah Polyclinic ## 6212000141 @ 473.xlsx\n",
      "Exported Shifa Buraydah Polyclinic ## 6212000141 @ 473.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:00:54\n",
      "\n",
      "Started mapping Shifa Jeddah Polyclinic ## 6212000304 @ 5903.xlsx\n",
      "Finished mapping Shifa Jeddah Polyclinic ## 6212000304 @ 5903.xlsx\n",
      "Exported Shifa Jeddah Polyclinic ## 6212000304 @ 5903.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:15\n",
      "\n",
      "Started mapping Specialized Medical Center Hospital ## 6212000401 @ 4306.xlsx\n",
      "Finished mapping Specialized Medical Center Hospital ## 6212000401 @ 4306.xlsx\n",
      "Exported Specialized Medical Center Hospital ## 6212000401 @ 4306.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:04:14\n",
      "\n",
      "Started mapping Taj General Specialty Medical & Diagnostic Center ## 6212000900 @ 636.xlsx\n",
      "Finished mapping Taj General Specialty Medical & Diagnostic Center ## 6212000900 @ 636.xlsx\n",
      "Exported Taj General Specialty Medical & Diagnostic Center ## 6212000900 @ 636.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:07\n",
      "\n",
      "Started mapping United Pharmaceutical Companies ## 6212001911 @ 7636.xlsx\n",
      "Finished mapping United Pharmaceutical Companies ## 6212001911 @ 7636.xlsx\n",
      "Exported United Pharmaceutical Companies ## 6212001911 @ 7636.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:04:15\n",
      "\n",
      "Started mapping Wahat Al Shifa Medical Center - 2 ## 6212001925 @ 8073.xlsx\n",
      "Finished mapping Wahat Al Shifa Medical Center - 2 ## 6212001925 @ 8073.xlsx\n",
      "Exported Wahat Al Shifa Medical Center - 2 ## 6212001925 @ 8073.xlsx to the 'Mapped Providers 2' folder\n",
      "Time: 00:01:56\n",
      "\n",
      "Wall time: 39min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 1\n",
    "for provider_path in get_providers_path()[23:]:\n",
    "    start_time = time.time()\n",
    "    print(\"Started mapping \" + os.path.basename(provider_path))\n",
    "    result = files_mapping(provider_path)\n",
    "    if len(result) > 0:\n",
    "        print(\"Finished mapping \" + os.path.basename(provider_path))\n",
    "        export_excel(provider_path)\n",
    "        print(\"Exported \" + os.path.basename(provider_path) + \" to the 'Mapped Providers 2' folder\")\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(\"Time: \" + str(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))) + \"\\n\")\n",
    "    else:\n",
    "        print(\"There is no mappings for this provider\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
